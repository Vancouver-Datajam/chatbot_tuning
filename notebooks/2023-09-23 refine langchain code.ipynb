{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# documents\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "# from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "# Creating the Agent\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Create memory \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Create the chain\n",
    "from langchain.chains import (\n",
    "    StuffDocumentsChain, LLMChain, ConversationalRetrievalChain\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_dict = dict()\n",
    "embeddings_dict = dict()\n",
    "db_dict = dict()\n",
    "retriever_dict = dict()\n",
    "vector_dict = dict()\n",
    "description_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict=dict()\n",
    "conversation_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='City of Vancouver\\n\\nhttps://vancouver.ca/home\\n\\n\\n\\nproperty\\n\\n\\n\\ndevelopment/apartments\\n\\n\\n\\ncondos\\n\\n\\n\\nand\\n\\n\\n\\ntownhomes.aspx\\n\\nApartments, condos, and townhomes\\n\\nWe do not provide waste collection services to most multi-unit buildings.\\n\\nHowever, we do provide information and resources to building owners and managers to manage waste at apartments, condos, and townhomes.\\n\\nWaste Management Canada collects your recycling on behalf of Recycle BC External website, opens in new tab Phone Waste Management Canada at 604-282-7961 for questions and issues about your recycling service.', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='City of Vancouver\\n\\nhttps://vancouver.ca/home\\n\\n\\n\\nproperty\\n\\n\\n\\ndevelopment/single\\n\\n\\n\\nfamily\\n\\n\\n\\nhomes\\n\\n\\n\\nand\\n\\n\\n\\nduplexes.aspx\\n\\nSingle family homes and duplexes We collect residential garbage, food scraps, and yard waste for single family homes and duplexes.\\n\\nYour household waste collection schedule is based on your location.\\n\\nRecycling: service is provided by GFL Environmental (formerly Smithrite Disposal Ltd) on behalf of Recycle BC External website, opens in new tab Phone 604-282-7966 or email srrecycle@gflenv.com about your recycling service, including:\\n\\nCollection questions or issues Replacing blue bins and recycling bags', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_documents(directory='../data/', glob='**/*.txt', show_progress=True):\n",
    "    loader = DirectoryLoader(directory, glob=glob, show_progress=show_progress)\n",
    "    documents = loader.load()\n",
    "    print(f'Number of files: {len(documents)}')\n",
    "    return documents\n",
    "\n",
    "documents = create_documents()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 33, which is longer than the specified 30\n",
      "Created a chunk of size 73, which is longer than the specified 30\n",
      "Created a chunk of size 134, which is longer than the specified 30\n",
      "Created a chunk of size 130, which is longer than the specified 30\n",
      "Created a chunk of size 67, which is longer than the specified 30\n",
      "Created a chunk of size 234, which is longer than the specified 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='City of Vancouver', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='https://vancouver.ca/home', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='property', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='development/apartments\\n\\ncondos', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='and\\n\\ntownhomes.aspx', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='Apartments, condos, and townhomes', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='We do not provide waste collection services to most multi-unit buildings.', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='However, we do provide information and resources to building owners and managers to manage waste at apartments, condos, and townhomes.', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='Waste Management Canada collects your recycling on behalf of Recycle BC External website, opens in new tab Phone Waste Management Canada at 604-282-7961 for questions and issues about your recycling service.', metadata={'source': '..\\\\data\\\\Vancouver apartments condos townhomes.txt'}),\n",
       " Document(page_content='City of Vancouver', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='https://vancouver.ca/home', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='property\\n\\ndevelopment/single', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='family\\n\\nhomes\\n\\nand', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='duplexes.aspx', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='Single family homes and duplexes We collect residential garbage, food scraps, and yard waste for single family homes and duplexes.', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='Your household waste collection schedule is based on your location.', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='Recycling: service is provided by GFL Environmental (formerly Smithrite Disposal Ltd) on behalf of Recycle BC External website, opens in new tab Phone 604-282-7966 or email srrecycle@gflenv.com about your recycling service, including:', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'}),\n",
       " Document(page_content='Collection questions or issues Replacing blue bins and recycling bags', metadata={'source': '..\\\\data\\\\Vancouver single family homes and duplexes.txt'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html?highlight=charactertextsplitter#langchain.text_splitter.CharacterTextSplitter.split_documents\n",
    "text_splitter = CharacterTextSplitter(chunk_size=30, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.schema.document.Document'>\n",
      "City of Vancouver\n"
     ]
    }
   ],
   "source": [
    "print(type(texts[0]))\n",
    "print(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CoV': VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000226CA1DC5D0>, search_type='similarity', search_kwargs={})}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_retriever(documents, site_key, vector_dict=vector_dict, text_splitter=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - text_splitter (optional): a text splitter object. If None, the documents are not split. \n",
    "    \"\"\"\n",
    "    embeddings_dict[site_key] = OpenAIEmbeddings()\n",
    "    if text_splitter is None: # object type is the same (class 'langchain.schema.document.Document') whether or not the documents are split\n",
    "        texts = documents\n",
    "    else:\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    vector_dict[site_key] = FAISS.from_documents(texts, embeddings_dict[site_key])\n",
    "    retriever_dict[site_key] = vector_dict[site_key].as_retriever()\n",
    "    return retriever_dict\n",
    "\n",
    "retriever_dict = create_retriever(documents, 'CoV')\n",
    "retriever_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retriever_dict['CoV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('CoV', VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x0000029FE0CCAF50>, search_type='similarity', search_kwargs={}))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x0000029FE0CCAF50>, search_type='similarity', search_kwargs={})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_dict['CoV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='search_CoV', description='Searches and returns documents regarding waste and recycling in the City of Vancouver.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method BaseRetriever.get_relevant_documents of VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000226CA1DC5D0>, search_type='similarity', search_kwargs={})>, coroutine=<bound method BaseRetriever.aget_relevant_documents of VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000226CA1DC5D0>, search_type='similarity', search_kwargs={})>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_tools_list(retriever_dict, description_dict):\n",
    "    \"\"\"\n",
    "    https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_toolkits.conversational_retrieval.tool.create_retriever_tool.html?highlight=create_retriever_tool#langchain.agents.agent_toolkits.conversational_retrieval.tool.create_retriever_tool\n",
    "    \"\"\"\n",
    "    tools_list = []\n",
    "    for site_key, retriever in retriever_dict.items():\n",
    "        tool_name = f'search_{site_key}'\n",
    "        tool = create_retriever_tool(retriever_dict[site_key], tool_name, description_dict[site_key])\n",
    "        tools_list.append(tool)\n",
    "    return tools_list\n",
    "\n",
    "description_dict['CoV'] = 'Searches and returns documents regarding waste and recycling in the City of Vancouver.'\n",
    "\n",
    "tools_list = create_tools_list(retriever_dict, description_dict)\n",
    "tools_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chatbot\n",
    "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html?highlight=chatopenai#langchain.chat_models.openai.ChatOpenAI\n",
    "\n",
    "Need to customize prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for ConversationalRetrievalChain\ncombine_docs_chain\n  field required (type=value_error.missing)\nquestion_generator\n  field required (type=value_error.missing)\nretriever\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\datajam-chatbot\\chatbot_tuning\\notebooks\\2023-09-23 refine langchain code.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m input_id \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhere do I recycle coffee cups in Vancouver?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m conversation_dict[conversation_id] \u001b[39m=\u001b[39m create_chatbot()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m answer_dict[input_id] \u001b[39m=\u001b[39m chat_with_chatbot(query, chat_dict[conversation_id])\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\datajam-chatbot\\chatbot_tuning\\notebooks\\2023-09-23 refine langchain code.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m template \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCombine the chat history and follow up question into \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39ma standalone question. Chat History: \u001b[39m\u001b[39m{chat_history}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFollow up question: \u001b[39m\u001b[39m{question}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# prompt = PromptTemplate.from_template(template)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# question_generator_chain = LLMChain(llm=llm, prompt=prompt)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# chain = ConversationalRetrievalChain(question_generator=question_generator_chain)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# result = qa({\"question\": user_input})\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m chain \u001b[39m=\u001b[39m ConversationalRetrievalChain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mYou are a helpful assistant who provides concise answers to residents in Metro Vancouver, Canada.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mTo make your answer more concise, you ask follow up questions if needed so you can provide the most relevant answer.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mGiven the following conversation and a follow up question, rephrase the follow up question \u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mto be a standalone question, in its original language.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mChat History:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{chat_history}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mFollow Up Input: \u001b[39m\u001b[39m{question}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mStandalone question:\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     input_variables\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchat_history\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     output_parser\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, partial_variables\u001b[39m=\u001b[39m{}, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     template\u001b[39m=\u001b[39mtemplate, template_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf-string\u001b[39m\u001b[39m'\u001b[39m, validate_template\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\datajam\\Lib\\site-packages\\langchain\\load\\serializable.py:75\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\datajam\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for ConversationalRetrievalChain\ncombine_docs_chain\n  field required (type=value_error.missing)\nquestion_generator\n  field required (type=value_error.missing)\nretriever\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_chatbot(tools_list=tools_list, verbose=True):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature = 0,\n",
    "        openai_organization=os.environ['openai_organization'],\n",
    "        openai_api_key=os.environ['openai_api_key'],\n",
    "        )\n",
    "\n",
    "    agent_executor = create_conversational_retrieval_agent(llm, tools_list, verbose)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    template = (\n",
    "        \"Combine the chat history and follow up question into \"\n",
    "        \"a standalone question. Chat History: {chat_history}\"\n",
    "        \"Follow up question: {question}\"\n",
    "    )\n",
    "    # prompt = PromptTemplate.from_template(template)\n",
    "    # question_generator_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # chain = ConversationalRetrievalChain(question_generator=question_generator_chain)\n",
    "    # qa = chain.from_llm(\n",
    "    #     llm, vector_dict[site_key].as_retriever(), memory=memory\n",
    "    #     )\n",
    "    # result = qa({\"question\": user_input})\n",
    "    chain = ConversationalRetrievalChain()\n",
    "    template = \"\"\"You are a helpful assistant who provides concise answers to residents in Metro Vancouver, Canada.\n",
    "    To make your answer more concise, you ask follow up questions if needed so you can provide the most relevant answer.\n",
    "    Given the following conversation and a follow up question, rephrase the follow up question \n",
    "    to be a standalone question, in its original language.\\n\\n\n",
    "    Chat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=['chat_history', 'question'], \n",
    "        output_parser=None, partial_variables={}, \n",
    "        template=template, template_format='f-string', validate_template=True)\n",
    "    chat = chain.from_llm(\n",
    "        llm, vector_dict[site_key].as_retriever(), memory=memory,\n",
    "        condense_question_prompt=prompt\n",
    "        )\n",
    "\n",
    "    return chat\n",
    "\n",
    "def chat_with_chatbot(user_input, chat, verbose=True):\n",
    "    result = qa({\"question\": user_input})\n",
    "    \n",
    "    return result\n",
    "\n",
    "conversation_id = 1\n",
    "input_id = 1\n",
    "\n",
    "query = \"Where do I recycle coffee cups in Vancouver?\"\n",
    "conversation_dict[conversation_id] = create_chatbot()\n",
    "answer_dict[input_id] = chat_with_chatbot(query, chat_dict[conversation_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'site_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\datajam-chatbot\\chatbot_tuning\\notebooks\\2023-09-23 refine langchain code.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m input_id \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhere do I recycle coffee cups in Vancouver?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m conversation_dict[conversation_id] \u001b[39m=\u001b[39m create_chatbot()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m answer_dict[input_id] \u001b[39m=\u001b[39m chat_with_chatbot(query, chat_dict[conversation_id])\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\datajam-chatbot\\chatbot_tuning\\notebooks\\2023-09-23 refine langchain code.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mYou are a helpful assistant who provides concise answers to residents in Metro Vancouver, Canada.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mTo make your answer more concise, you ask follow up questions if needed so you can provide the most relevant answer.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mWhere relevant, you retrieve the relevant information from your documents to answer the resident\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms question.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mHere is your chat history with the resident: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{chat_history}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mRespond to the resident\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms query, which are delimited by triple backticks: ```\u001b[39m\u001b[39m{question}\u001b[39;00m\u001b[39m```\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     input_variables\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchat_history\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     output_parser\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, partial_variables\u001b[39m=\u001b[39m{}, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     template\u001b[39m=\u001b[39mtemplate, template_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf-string\u001b[39m\u001b[39m'\u001b[39m, validate_template\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m chat \u001b[39m=\u001b[39m ConversationalRetrievalChain\u001b[39m.\u001b[39mfrom_llm(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     llm, vector_dict[site_key]\u001b[39m.\u001b[39mas_retriever(), memory\u001b[39m=\u001b[39mmemory,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     condense_question_prompt\u001b[39m=\u001b[39mprompt\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/datajam-chatbot/chatbot_tuning/notebooks/2023-09-23%20refine%20langchain%20code.ipynb#X62sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m chat\n",
      "\u001b[1;31mNameError\u001b[0m: name 'site_key' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_chatbot(tools_list=tools_list, verbose=True):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature = 0,\n",
    "        openai_organization=os.environ['openai_organization'],\n",
    "        openai_api_key=os.environ['openai_api_key'],\n",
    "        )\n",
    "\n",
    "    agent_executor = create_conversational_retrieval_agent(llm, tools_list, verbose)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    template = (\n",
    "        \"Combine the chat history and follow up question into \"\n",
    "        \"a standalone question. Chat History: {chat_history}\"\n",
    "        \"Follow up question: {question}\"\n",
    "    )\n",
    "    template = \"\"\"You are a helpful assistant who provides concise answers to residents in Metro Vancouver, Canada.\n",
    "    To make your answer more concise, you ask follow up questions if needed so you can provide the most relevant answer.\n",
    "    Where relevant, you retrieve the relevant information from your documents to answer the resident's question.\n",
    "    Here is your chat history with the resident: \\n\\n{chat_history}\\n\\n\n",
    "    Respond to the resident's query, which are delimited by triple backticks: ```{question}```\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=['chat_history', 'question'], \n",
    "        output_parser=None, partial_variables={}, \n",
    "        template=template, template_format='f-string', validate_template=True)\n",
    "    chat = ConversationalRetrievalChain.from_llm(\n",
    "        llm, vector_dict[site_key].as_retriever(), memory=memory,\n",
    "        condense_question_prompt=prompt\n",
    "        )\n",
    "\n",
    "    return chat\n",
    "\n",
    "def chat_with_chatbot(user_input, chat, verbose=True):\n",
    "    result = qa({\"question\": user_input})\n",
    "    \n",
    "    return result\n",
    "\n",
    "conversation_id = 1\n",
    "input_id = 1\n",
    "\n",
    "query = \"Where do I recycle coffee cups in Vancouver?\"\n",
    "conversation_dict[conversation_id] = create_chatbot()\n",
    "answer_dict[input_id] = chat_with_chatbot(query, chat_dict[conversation_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_chatbot(tools_list=tools_list, vector_store=vector_dict['CoV'], verbose=True):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature = 0,\n",
    "        openai_organization=os.environ['openai_organization'],\n",
    "        openai_api_key=os.environ['openai_api_key'],\n",
    "        )\n",
    "\n",
    "    agent_executor = create_conversational_retrieval_agent(llm, tools_list, verbose)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    template = (\n",
    "        \"Combine the chat history and follow up question into \"\n",
    "        \"a standalone question. Chat History: {chat_history}\"\n",
    "        \"Follow up question: {question}\"\n",
    "    )\n",
    "    template = \"\"\"You are a helpful assistant who provides concise answers to residents in Metro Vancouver, Canada.\n",
    "    To make your answer more concise, you ask follow up questions if needed so you can provide the most relevant answer.\n",
    "    Where relevant, you retrieve the relevant information from your documents to answer the resident's question.\n",
    "    Here is your chat history with the resident: \\n\\n{chat_history}\\n\\n\n",
    "    Respond to the resident's query, which are delimited by triple backticks: ```{question}```\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=['chat_history', 'question'], \n",
    "        output_parser=None, partial_variables={}, \n",
    "        template=template, template_format='f-string', validate_template=True)\n",
    "    chat = ConversationalRetrievalChain.from_llm(\n",
    "        llm, vector_store.as_retriever(), memory=memory,\n",
    "        condense_question_prompt=prompt\n",
    "        )\n",
    "\n",
    "    return chat\n",
    "\n",
    "def chat_with_chatbot(user_input, chat, verbose=True):\n",
    "    result = chat({\"question\": user_input})\n",
    "    \n",
    "    return result\n",
    "\n",
    "conversation_id = 1\n",
    "input_id = 1\n",
    "\n",
    "query = \"Where do I recycle coffee cups in Vancouver?\"\n",
    "conversation_dict[conversation_id] = create_chatbot()\n",
    "answer_dict[input_id] = chat_with_chatbot(query, conversation_dict[conversation_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where do I recycle coffee cups in Vancouver?',\n",
       " 'chat_history': [HumanMessage(content='Where do I recycle coffee cups in Vancouver?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='For single-family homes and duplexes in Vancouver, you can recycle coffee cups in your blue bin provided by GFL Environmental. You can contact GFL Environmental at 604-282-7966 or email srrecycle@gflenv.com for any questions or issues regarding your recycling service, including coffee cup recycling.\\n\\nFor apartments, condos, and townhomes, waste collection services are not provided by the City of Vancouver. Waste Management Canada collects recycling on behalf of Recycle BC for these types of buildings. You can contact Waste Management Canada at 604-282-7961 for questions and issues about recycling, including coffee cup recycling.', additional_kwargs={}, example=False)],\n",
       " 'answer': 'For single-family homes and duplexes in Vancouver, you can recycle coffee cups in your blue bin provided by GFL Environmental. You can contact GFL Environmental at 604-282-7966 or email srrecycle@gflenv.com for any questions or issues regarding your recycling service, including coffee cup recycling.\\n\\nFor apartments, condos, and townhomes, waste collection services are not provided by the City of Vancouver. Waste Management Canada collects recycling on behalf of Recycle BC for these types of buildings. You can contact Waste Management Canada at 604-282-7961 for questions and issues about recycling, including coffee cup recycling.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict[input_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "For single-family homes and duplexes in Vancouver, you can recycle coffee cups in your blue bin provided by GFL Environmental. You can contact GFL Environmental at 604-282-7966 or email srrecycle@gflenv.com for any questions or issues regarding your recycling service, including coffee cup recycling.\n",
      "\n",
      "For apartments, condos, and townhomes, waste collection services are not provided by the City of Vancouver. Waste Management Canada collects recycling on behalf of Recycle BC for these types of buildings. You can contact Waste Management Canada at 604-282-7961 for questions and issues about recycling, including coffee cup recycling.\n"
     ]
    }
   ],
   "source": [
    "print(len(answer_dict[input_id]['answer']))\n",
    "print(answer_dict[input_id]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
